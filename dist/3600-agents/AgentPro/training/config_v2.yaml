# Training Configuration v2 for AgentPro
# 30k positions with improved anti-repetition heuristics

data:
  train_file: 'training_data_v2.json'
  val_split: 0.12           # 12% validation (3.6k positions)
  test_split: 0.08          # 8% test (2.4k positions)
  augment: true
  noise_level: 0.01         # Light noise for regularization

model:
  input_size: 128           # Full feature vector!
  hidden_size: 320          # Increased from 256 (more capacity for 30k data)
  num_residual_blocks: 4    # Increased from 3
  dropout: 0.3              # Keep dropout same

training:
  epochs: 400               # Train longer
  batch_size: 512           # Larger batches for H100
  learning_rate: 0.0005     # Lower LR for stability
  weight_decay: 0.0001
  gradient_clip: 1.0
  betas: [0.9, 0.999]

  # Mixed precision for H100 speed
  use_amp: true

  # Learning rate schedule
  scheduler:
    type: 'reduce_on_plateau'
    factor: 0.5
    patience: 15            # More patience
    min_lr: 0.000001

  # Early stopping
  early_stopping:
    patience: 40            # Much more patience
    min_delta: 0.0001

# Checkpointing
checkpoint:
  save_every_n_epochs: 20
  save_every_n_minutes: 60
  keep_best: 5              # Keep top 5 models

# Logging
logging:
  use_tensorboard: true
  tensorboard_dir: 'runs_v2'
  log_every_n_batches: 25
  print_every_n_epochs: 1

# Hardware
hardware:
  device: 'cuda'
  num_workers: 8            # Optimized for 30k dataset
  pin_memory: true

# Data generation (for reference)
data_generation:
  num_positions: 30000
  depth_for_labels: 9
  num_processes: 32
  min_moves: 8
  max_moves: 30
  move_variety: 'weighted'
